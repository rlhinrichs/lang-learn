accelerate==1.7.0
aiohappyeyeballs==2.6.1
aiohttp==3.11.18
aiosignal==1.3.2
async-timeout==5.0.1
attrs==25.3.0
bitsandbytes==0.45.5
certifi==2025.4.26
charset-normalizer==3.4.2
colorama==0.4.6
datasets==3.6.0
dill==0.3.8
einops==0.8.1
filelock==3.13.1
frozenlist==1.6.0
fsspec==2024.6.1
huggingface-hub==0.31.4
idna==3.10
Jinja2==3.1.4
joblib==1.5.0
MarkupSafe==2.1.5
mpmath==1.3.0
multidict==6.4.4
multiprocess==0.70.16
networkx==3.3
numpy==2.1.2
packaging==25.0
pandas==2.2.3
peft==0.15.2
pillow==11.0.0
propcache==0.3.1
psutil==7.0.0
pyarrow==20.0.0
python-dateutil==2.9.0.post0
pytz==2025.2
PyYAML==6.0.2
regex==2024.11.6
requests==2.32.3
safetensors==0.5.3
scikit-learn==1.6.1
scipy==1.15.3
six==1.17.0
sympy==1.13.1
threadpoolctl==3.6.0
tokenizers==0.21.1
torch==2.5.1+cu121
torchaudio==2.5.1+cu121
torchvision==0.20.1+cu121
tqdm==4.67.1
transformers==4.52.2
typing_extensions==4.12.2
tzdata==2025.2
urllib3==2.4.0
xxhash==3.5.0
yarl==1.20.0

conda activate py310-gpu
pip install torch transformers huggingface-hub tokenizers scikit-learn

1- import the base model (full weights) & tokenizer, save to local

2- inspect files: ls -lh /home/user/models/falcon-7b
total 26G
-rw-r--r-- 1 user user 1.2K May 24 17:43 config.json
-rw-r--r-- 1 user user  113 May 24 17:43 generation_config.json
-rw-r--r-- 1 user user 4.7G May 24 17:43 model-00001-of-00006.safetensors
-rw-r--r-- 1 user user 4.7G May 24 17:43 model-00002-of-00006.safetensors
-rw-r--r-- 1 user user 4.7G May 24 17:44 model-00003-of-00006.safetensors
-rw-r--r-- 1 user user 4.7G May 24 17:44 model-00004-of-00006.safetensors
-rw-r--r-- 1 user user 4.7G May 24 17:44 model-00005-of-00006.safetensors
-rw-r--r-- 1 user user 2.7G May 24 17:44 model-00006-of-00006.safetensors
-rw-r--r-- 1 user user  17K May 24 17:44 model.safetensors.index.json
-rw-r--r-- 1 user user  395 May 24 17:44 special_tokens_map.json
-rw-r--r-- 1 user user 4.4M May 24 17:44 tokenizer.json
-rw-r--r-- 1 user user 2.6K May 24 17:44 tokenizer_config.json

adjust 'test_query.py' with user home directory

1- train the adapter weights (12 hrs) using QLoRA
adapter weights fitted on LLM Falcon-7B

2- 